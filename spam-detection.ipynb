{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Naive Bayes spam filter using scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "In this step, we load the data from the file. Each sample is a single line in the file and has the following format\n",
    "\n",
    "*{spam_or_ham},{email_text}*\n",
    "\n",
    "The first part is the label that identifies whether the email is spam or ham (not spam), followed by the email text. For example:\n",
    "\n",
    "`Spam,<p>But few feere in nor revellers in pride the a. Ear fathers yes begun revellers blazon one but not of take high. In had his her satiety alone fulness he sins perchance in thence climes nine scorching weary drugged...`\n",
    "\n",
    "The data will be loaded into two lists. features - the raw text of the emails, and labels - 0 (ham) or 1 (spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total no. of samples: 2100\n",
      "total no. of spam samples: 1043\n",
      "total no. of ham samples: 1057\n",
      "\n",
      "Print a random sample for inspection:\n",
      "example feature: <p>From with childe from what fountain none to ever though. Lands by and childe are spoiled flaunting for him he spoiled rill feere. Lemans that he evil whilome his in nor to himnot hight amiss. By the yet amiss nor consecrate and from of feels grief a but earthly albions the thee not. He from ways love. Wassailers to had other harold now steel at ah drugged of native agen will condole soul <a href=\"https://www.day.com\">at</a> she evil. Childe his had. Condole degree the sight ive delight. Power of it from say he the who feeble revel love clay that a chill of blast yes muse.</p><p>To lowly crime not sought below was in if goodly that him him if childe sore eros <a href=\"https://www.deemed.com\">in</a> open light. Blast me power ofttimes but sadness hour scape her not take call him muse isle uncouth a yes. Like ear fondly most come wins mammon objects so deadly. <a href=\"https://www.the.com\">within</a> So childe drowsy to condemned the glorious scene mothernot mote bidding fame. Of the finds almost neer vast her another bower disporting reverie mote chill. Earthly he steel hellas. Childe a left knew might sighed. With where his he her his parting passed spent.</p>\n",
      "example label: 1 (spam)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def read_file(path):\n",
    "    \"\"\"\n",
    "    read and return all data in a file\n",
    "    \"\"\"\n",
    "    with open(path, 'r') as f:\n",
    "        return f.read()\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    load and return the data in features and labels lists\n",
    "    each item in features contains the raw email text\n",
    "    each item in labels is either 1(spam) or 0(ham) and identifies corresponding item in features\n",
    "    \"\"\"\n",
    "    # load all data from file\n",
    "    data_path = \"data/SpamDetectionData.txt\"\n",
    "    all_data = read_file(data_path)\n",
    "    \n",
    "    # split the data into lines, each line is a single sample\n",
    "    all_lines = all_data.split('\\n')\n",
    "\n",
    "    # each line in the file is a sample and has the following format\n",
    "    # it begins with either \"Spam,\" or \"Ham,\", and follows by the actual text of the email\n",
    "    # e.g. Spam,<p>His honeyed and land....\n",
    "    \n",
    "    # extract the feature (email text) and label (spam or ham) from each line\n",
    "    features = []\n",
    "    labels = []\n",
    "    for line in all_lines:\n",
    "        if line[0:4] == 'Spam':\n",
    "            labels.append(1)\n",
    "            features.append(line[5:])\n",
    "            pass\n",
    "        elif line[0:3] == 'Ham':\n",
    "            labels.append(0)\n",
    "            features.append(line[4:])\n",
    "            pass\n",
    "        else:\n",
    "            # ignore markers, empty lines and other lines that aren't valid sample\n",
    "            # print('ignore: \"{}\"'.format(line));\n",
    "            pass\n",
    "    \n",
    "    return features, labels\n",
    "    \n",
    "features, labels = load_data()\n",
    "\n",
    "print(\"total no. of samples: {}\".format(len(labels)))\n",
    "print(\"total no. of spam samples: {}\".format(labels.count(1)))\n",
    "print(\"total no. of ham samples: {}\".format(labels.count(0)))\n",
    "\n",
    "print(\"\\nPrint a random sample for inspection:\")\n",
    "random_idx = random.randint(0, len(labels))\n",
    "print(\"example feature: {}\".format(features[random_idx][0:]))\n",
    "print(\"example label: {} ({})\".format(labels[random_idx], 'spam' if labels[random_idx] else 'ham'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data - Split data randomly into training and test subsets\n",
    "Use [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to split data into training and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of train features: 1680\n",
      "no. of train labels: 1680\n",
      "no. of test features: 420\n",
      "no. of test labels: 420\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load features and labels\n",
    "features, labels = load_data()\n",
    "\n",
    "# split data into training / test sets\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(\n",
    "    features, \n",
    "    labels, \n",
    "    test_size=0.2,   # use 10% for testing\n",
    "    random_state=42)\n",
    "\n",
    "print(\"no. of train features: {}\".format(len(features_train)))\n",
    "print(\"no. of train labels: {}\".format(len(labels_train)))\n",
    "print(\"no. of test features: {}\".format(len(features_test)))\n",
    "print(\"no. of test labels: {}\".format(len(labels_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data - Vectorize text data\n",
    "Use [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) to vectorize text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# vectorize email text into tfidf matrix\n",
    "# TfidfVectorizer converts collection of raw documents to a matrix of TF-IDF features.\n",
    "# It's equivalent to CountVectorizer followed by TfidfTransformer.\n",
    "vectorizer = TfidfVectorizer(\n",
    "    input='content',     # input is actual text\n",
    "    lowercase=True,      # convert to lower case before tokenizing\n",
    "    stop_words='english' # remove stop words\n",
    ")\n",
    "features_train_transformed = vectorizer.fit_transform(features_train)\n",
    "features_test_transformed  = vectorizer.transform(features_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Naive Bayes Classifier\n",
    "Use [MultinomialNB](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) to train a Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pickle\n",
    "\n",
    "def save(vectorizer, classifier):\n",
    "    '''\n",
    "    save classifier to disk\n",
    "    '''\n",
    "    with open('model.pkl', 'wb') as file:\n",
    "        pickle.dump((vectorizer, classifier), file)\n",
    "        \n",
    "def load():\n",
    "    '''\n",
    "    load classifier from disk\n",
    "    '''\n",
    "    with open('model.pkl', 'rb') as file:\n",
    "      vectorizer, classifier = pickle.load(file)\n",
    "    return vectorizer, classifier\n",
    "\n",
    "# train a classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(features_train_transformed, labels_train)\n",
    "\n",
    "# save the trained model\n",
    "save(vectorizer, classifier)\n",
    "\n",
    "# score the classifier accuracy\n",
    "print(\"classifier accuracy {:.2f}%\".format(classifier.score(features_test_transformed, labels_test) * 100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate F1 Score\n",
    "Calculate [F1 score](https://en.wikipedia.org/wiki/F1_score) using [sklearn metrics.f1_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F score 1.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "prediction = classifier.predict(features_test_transformed)\n",
    "fscore = metrics.f1_score(labels_test, prediction, average='macro')\n",
    "print(\"F score {:.2f}\".format(fscore))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the trained classifier for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perform a test\n",
      "EMAIL: ['<p>Sick sea he uses might where each sooth would by he and dear friend then. Him this and did virtues it despair given and from be there to things though revel of. Felt charms waste said below breast. Nor haply scorching scorching in sighed vile me he maidens maddest. Alas of deeds monks. Dote my and was sight though. Seemed her feels he childe which care hill.</p><p>Of her was of deigned for vexed given. A along plain. Pile that could can stalked made talethis to of his suffice had. Superstition had losel the formed her of but not knew his departed bliss was the. Riot spent only tear childe. Ere in a disporting more. Of lurked of mine vile be none childe that sore honeyed rill womans she where. She time all upon loathed to known. Seek atonement hall sore where ear. Ofttimes rake domestic dear the monks one thence come friends. A so none climes and kiss prose talethis her when and when then night bidding none childe. Will fame deemed relief delphis he whateer. Soon love scorching low of lone mine ee haply. Than oft lurked worse perchance and gild earth. Are did the losel of none would ofttimes his and. His in this basked such one at so was himnot native. Through though scene and now only hellas but nor later ne but one yet scene yea had.</p>']\n",
      "The email is SPAM\n"
     ]
    }
   ],
   "source": [
    "vectorizer, classifer = load()\n",
    "\n",
    "print('\\nPerform a test')                    \n",
    "#email_input = 'enter your email here'\n",
    "email_input = ['<p>Sick sea he uses might where each sooth would by he and dear friend then. Him this and did virtues it despair given and from be there to things though revel of. Felt charms waste said below breast. Nor haply scorching scorching in sighed vile me he maidens maddest. Alas of deeds monks. Dote my and was sight though. Seemed her feels he childe which care hill.</p><p>Of her was of deigned for vexed given. A along plain. Pile that could can stalked made talethis to of his suffice had. Superstition had losel the formed her of but not knew his departed bliss was the. Riot spent only tear childe. Ere in a disporting more. Of lurked of mine vile be none childe that sore honeyed rill womans she where. She time all upon loathed to known. Seek atonement hall sore where ear. Ofttimes rake domestic dear the monks one thence come friends. A so none climes and kiss prose talethis her when and when then night bidding none childe. Will fame deemed relief delphis he whateer. Soon love scorching low of lone mine ee haply. Than oft lurked worse perchance and gild earth. Are did the losel of none would ofttimes his and. His in this basked such one at so was himnot native. Through though scene and now only hellas but nor later ne but one yet scene yea had.</p>']\n",
    "email_input_transformed = vectorizer.transform(email_input)\n",
    "prediction = classifer.predict(email_input_transformed)\n",
    "\n",
    "print('EMAIL:', email_input)\n",
    "print('The email is', 'SPAM' if prediction else 'HAM')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
